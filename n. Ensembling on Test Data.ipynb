{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dask.array.image import imread\n",
    "from dask import bag, threaded\n",
    "from dask.diagnostics import ProgressBar\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense,GlobalAveragePooling2D\n",
    "from keras.layers import Flatten,Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images read: 1000\n",
      "Number of images read: 2000\n",
      "Number of images read: 3000\n",
      "Number of images read: 4000\n",
      "Number of images read: 5000\n",
      "Number of images read: 6000\n",
      "Number of images read: 7000\n",
      "Number of images read: 8000\n",
      "Number of images read: 9000\n",
      "Number of images read: 10000\n",
      "Number of images read: 11000\n",
      "Number of images read: 12000\n",
      "Number of images read: 13000\n",
      "Number of images read: 14000\n",
      "Number of images read: 15000\n",
      "Number of images read: 16000\n",
      "Number of images read: 17000\n",
      "Number of images read: 18000\n",
      "Number of images read: 19000\n",
      "Number of images read: 20000\n",
      "Number of images read: 21000\n",
      "Number of images read: 22000\n",
      "Number of images read: 23000\n",
      "Number of images read: 24000\n",
      "Number of images read: 25000\n",
      "Number of images read: 26000\n",
      "Number of images read: 27000\n",
      "Number of images read: 28000\n",
      "Number of images read: 29000\n",
      "Number of images read: 30000\n",
      "Number of images read: 31000\n",
      "Number of images read: 32000\n",
      "Number of images read: 33000\n",
      "Number of images read: 34000\n",
      "Number of images read: 35000\n",
      "Number of images read: 36000\n",
      "Number of images read: 37000\n",
      "Number of images read: 38000\n",
      "Number of images read: 39000\n",
      "Number of images read: 40000\n",
      "Number of images read: 41000\n",
      "Number of images read: 42000\n",
      "Number of images read: 43000\n",
      "Number of images read: 44000\n",
      "Number of images read: 45000\n",
      "Number of images read: 46000\n",
      "Number of images read: 47000\n",
      "Number of images read: 48000\n",
      "Number of images read: 49000\n",
      "Number of images read: 50000\n",
      "Number of images read: 51000\n",
      "Number of images read: 52000\n",
      "Number of images read: 53000\n",
      "Number of images read: 54000\n",
      "Number of images read: 55000\n",
      "Number of images read: 56000\n",
      "Number of images read: 57000\n",
      "Number of images read: 58000\n",
      "Number of images read: 59000\n",
      "Number of images read: 60000\n",
      "Number of images read: 61000\n",
      "Number of images read: 62000\n",
      "Number of images read: 63000\n",
      "Number of images read: 64000\n",
      "Number of images read: 65000\n",
      "Number of images read: 66000\n",
      "Number of images read: 67000\n",
      "Number of images read: 68000\n",
      "Number of images read: 69000\n",
      "Number of images read: 70000\n",
      "Number of images read: 71000\n",
      "Number of images read: 72000\n",
      "Number of images read: 73000\n",
      "Number of images read: 74000\n",
      "Number of images read: 75000\n",
      "Number of images read: 76000\n",
      "Number of images read: 77000\n",
      "Number of images read: 78000\n",
      "Number of images read: 79000\n",
      "All images are loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Getting all the images\n",
    "\n",
    "val_image = []\n",
    "\n",
    "\n",
    "imgs = sorted(os.listdir('/home/jupyter/Test_Images/test'))\n",
    "\n",
    "cntr = 0\n",
    "l = 0\n",
    "\n",
    "for j in range(len(imgs)):\n",
    "    img_name = \"/home/jupyter/Test_Images/test\"+\"/\"+imgs[j]\n",
    "    img = cv2.imread(img_name)\n",
    "    #img = color.rgb2gray(img)\n",
    "    img = img[50:,120:-50]\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    val_image.append(img)\n",
    "    cntr = cntr+1\n",
    "    if cntr == 1000:\n",
    "        l = l+1\n",
    "        print ('Number of images read:',l*1000)\n",
    "        cntr = 0\n",
    "\n",
    "print('All images are loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726\n"
     ]
    }
   ],
   "source": [
    "## Splitting the train and test\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for features in val_image:\n",
    "    X_test.append(features)\n",
    "    \n",
    "\n",
    "print (len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79726, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "## Converting images to nparray. Encoding the Y\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1,224,224,3)\n",
    "\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception Model: Extra Layers - Accuracy 82.5% Loss 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model is Loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "xception_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "## The RESNET model\n",
    "\n",
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "\n",
    "#Get the RESNET weights and layers\n",
    "\n",
    "model_xception_conv = Xception(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "output_xception_conv = model_xception_conv(xception_input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "\n",
    "x=GlobalAveragePooling2D()(output_xception_conv)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dropout(0.1)(x) # **reduce dropout \n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,activation='relu')(x) #dense layer 3\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "\n",
    "xception_pretrained = Model(input = xception_input, output = x)\n",
    "\n",
    "xception_pretrained = Model(input = xception_input, output = x)\n",
    "xception_pretrained.load_weights('xception_weights_aug_extralayer_alltrained_sgd2_V2.hdf5')\n",
    "\n",
    "print('Model is Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model1_prediction = []\n",
    "model1_pred_class = []\n",
    "\n",
    "model1_prediction = xception_pretrained.predict(X_test)\n",
    "print('Images Predicted until now:',len(model1_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception Model: No Extra Layers - Accuracy 82.8% Loss 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "xception_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "## The RESNET model\n",
    "\n",
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "\n",
    "#Get the RESNET weights and layers\n",
    "\n",
    "model_xception_conv = Xception(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "output_xception_conv = model_xception_conv(xception_input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "\n",
    "x = Flatten(name='flatten')(output_xception_conv)\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "\n",
    "xception_pretrained = Model(input = xception_input, output = x)\n",
    "\n",
    "xception_pretrained = Model(input = xception_input, output = x)\n",
    "xception_pretrained.load_weights('xception_weights_aug_alltrained_setval_sgd3.hdf5')\n",
    "\n",
    "print('Model is Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "model2_prediction = []\n",
    "model2_pred_class = []\n",
    "\n",
    "model2_prediction = xception_pretrained.predict(X_test)\n",
    "print('Images Predicted until now:',len(model2_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET 50 Model: No Extra Layers - Accuracy 85.43% Loss 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "resnet50_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "model_resnet50_conv = ResNet50(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
    "\n",
    "output_resnet50_conv = model_resnet50_conv(resnet50_input)\n",
    "\n",
    "x = Flatten(name='flatten')(output_resnet50_conv)\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "resnet50_pretrained = Model(input = resnet50_input, output = x)\n",
    "\n",
    "resnet50_pretrained.load_weights('resnet_weights_aug_alltrained_sgd2_setval.hdf5')\n",
    "\n",
    "print('Model is Loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "\n",
    "model3_prediction = []\n",
    "model3_pred_class = []\n",
    "\n",
    "model3_prediction = resnet50_pretrained.predict(X_test)\n",
    "print('Images Predicted until now:',len(model3_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET 50 Model: Extra Layers - Accuracy 86.43% Loss 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "resnet50_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "## The RESNET model\n",
    "model_resnet50_conv = ResNet50(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
    "\n",
    "\n",
    "\n",
    "output_resnet50_conv = model_resnet50_conv(resnet50_input)\n",
    "x=GlobalAveragePooling2D()(output_resnet50_conv)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dropout(0.1)(x) # **reduce dropout \n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "\n",
    "resnet50_pretrained = Model(input = resnet50_input, output = x)\n",
    "\n",
    "resnet50_pretrained.load_weights('resnet_weights_aug_extralayers_sgd_setval.hdf5')\n",
    "\n",
    "\n",
    "print('Model is loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "\n",
    "model4_prediction = []\n",
    "model4_pred_class = []\n",
    "\n",
    "model4_prediction = resnet50_pretrained.predict(X_test)\n",
    "print('Images Predicted until now:',len(model4_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 16 Model: No Extra Layers - Accuracy 84.7% Loss 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model is loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "vgg16_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_tensor = vgg16_input)\n",
    "\n",
    "\n",
    "\n",
    "output_vgg16_conv = model_vgg16_conv(vgg16_input)\n",
    "\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "vgg16_pretrained = Model(input = vgg16_input, output = x)\n",
    "\n",
    "\n",
    "vgg16_pretrained.load_weights('vgg_weights_aug_setval_sgd.hdf5')\n",
    "\n",
    "print('The Model is loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "\n",
    "model5_prediction = []\n",
    "model5_pred_class = []\n",
    "\n",
    "model5_prediction = vgg16_pretrained.predict(X_test)\n",
    "print('Images Predicted until now:',len(model5_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 16 Model: Extra Layers - Accuracy 81.5% Loss 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model is loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "vgg16_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_tensor = vgg16_input)\n",
    "\n",
    "\n",
    "\n",
    "output_vgg16_conv = model_vgg16_conv(vgg16_input)\n",
    "\n",
    "x=GlobalAveragePooling2D()(output_vgg16_conv)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dropout(0.1)(x) # **reduce dropout \n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,activation='relu')(x) #dense layer 3\n",
    "x = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "vgg16_pretrained = Model(input = vgg16_input, output = x)\n",
    "\n",
    "\n",
    "vgg16_pretrained.load_weights('vgg_weights_aug_setval_layers_sgd2.hdf5')\n",
    "\n",
    "print('The Model is loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels is the image array\n",
    "\n",
    "\n",
    "model6_prediction = []\n",
    "model6_pred_class = []\n",
    "\n",
    "model6_prediction = vgg16_pretrained.predict(X_test)\n",
    "print('Images Predicted until now:',len(model6_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet Model: Extra Layers - Accuracy 83.6% Loss 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model is loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "mbnet_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "\n",
    "model_mbnet_conv = MobileNet(weights='imagenet',include_top=False)\n",
    "\n",
    "\n",
    "x=model_mbnet_conv.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x = Dropout(0.1)(x) # ****reduce dropout \n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(10,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "mbnet_model = Model(inputs=model_mbnet_conv.input, outputs=preds)\n",
    "\n",
    "mbnet_model.load_weights('mobilenet_weights_1103.hdf5')\n",
    "\n",
    "print('The Model is loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "\n",
    "model7_prediction = []\n",
    "model7_pred_class = []\n",
    "\n",
    "model7_prediction = mbnet_model.predict(X_test)\n",
    "print('Images Predicted until now:',len(model7_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet Model: No Extra Layers - Accuracy 85.7% Loss 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model is loaded\n"
     ]
    }
   ],
   "source": [
    "## Defining the input\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "mbnet_input = Input(shape = (224, 224, 3), name = 'Image_input')\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "\n",
    "model_mbnet_conv = MobileNet(weights='imagenet',include_top=False)\n",
    "\n",
    "\n",
    "x=model_mbnet_conv.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "preds=Dense(10,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "mbnet_model = Model(inputs=model_mbnet_conv.input, outputs=preds)\n",
    "\n",
    "mbnet_model.load_weights('mobilenet_sgd_nolayers.hdf5')\n",
    "\n",
    "print('The Model is loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Predicted until now: 79726\n"
     ]
    }
   ],
   "source": [
    "# labels is the image array\n",
    "\n",
    "\n",
    "model8_prediction = []\n",
    "model8_pred_class = []\n",
    "\n",
    "model8_prediction = mbnet_model.predict(X_test)\n",
    "print('Images Predicted until now:',len(model8_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean,median\n",
    "predictions = []\n",
    "ensemble_predictions = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "#for i in range(1):\n",
    "    mean_prediction = []\n",
    "    \n",
    "    for j in range(10):\n",
    "        #predictions.append(model1_prediction[i][j])\n",
    "        #predictions.append(model2_prediction[i][j])\n",
    "        #predictions.append(model3_prediction[i][j])\n",
    "        #predictions.append(model4_prediction[i][j])\n",
    "        #predictions.append(model5_prediction[i][j])\n",
    "        #predictions.append(model6_prediction[i][j])\n",
    "        predictions.append(model7_prediction[i][j])\n",
    "        #predictions.append(model8_prediction[i][j])\n",
    "        #print(predictions)\n",
    "        \n",
    "        trimmed_value = (sum(predictions) - max(predictions) - min(predictions))/(len(predictions) - 2)\n",
    "        \n",
    "        mean_value = mean(predictions)\n",
    "\n",
    "        predictions = []\n",
    "        mean_prediction.append(trimmed_value)\n",
    "        #mean_prediction.append(mean_value)\n",
    "    \n",
    "    mean_prediction = mean_prediction/ sum(mean_prediction)\n",
    "    ensemble_predictions.append(mean_prediction)\n",
    "        \n",
    "    \n",
    "#ensemble_predictions = np.asarray(ensemble_predictions)        \n",
    "print('Got predictions from ensemble')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(ensemble_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['Images'] = pd.Series(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('EnsemblePredictions_M2,3,5,7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_pred = pd.DataFrame(model8_prediction)\n",
    "df_pred['Images'] = pd.Series(imgs)\n",
    "df_pred.to_csv('Model6_Predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
